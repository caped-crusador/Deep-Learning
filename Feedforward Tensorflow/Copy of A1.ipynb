{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of A1.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"1hMHUUbBDjoXO70Lqv-GyDOc1NbSsb4cu","timestamp":1526480257802}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"sKGsmsab5I1S","colab_type":"text"},"cell_type":"markdown","source":["# <center>Assignment 1</center>"]},{"metadata":{"id":"q5VD__J65I1U","colab_type":"text"},"cell_type":"markdown","source":["There are 2 main parts asked in this assignment - Tensorflow Basics and Neural Networks. You can choose to code in Python2 or Python3. All the imports made in this notebook are as below; if these imports work, you are (mostly) set to complete the assignment."]},{"metadata":{"id":"B4teB1gh5I1V","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from __future__ import print_function,division\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import random \n","import tensorflow as tf\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vWzfE86tusct","colab_type":"text"},"cell_type":"markdown","source":["## Tensorflow - Basics"]},{"metadata":{"id":"gtgV4CJM5I1Z","colab_type":"text"},"cell_type":"markdown","source":["### I. Linear Regression"]},{"metadata":{"id":"waXA1j7A5I1a","colab_type":"text"},"cell_type":"markdown","source":["<b>1a. Creating Sample Data </b>"]},{"metadata":{"id":"LrDL6noo5I1b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = np.random.randn(100,3) # 100 data points of dimension 3\n","w = np.array([[1],[2],[3]])\n","b = 10\n","y = None # Write code to create the target. Use Numpy operations"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J6m9Ibn65QcP","colab_type":"text"},"cell_type":"markdown","source":["**1b. Plot Data**"]},{"metadata":{"id":"lS4Hlv8k5UeZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Explore the data by plotting whatever makes you understand the problem better. \n","# Your code here."],"execution_count":0,"outputs":[]},{"metadata":{"id":"qo8hagle5I1c","colab_type":"text"},"cell_type":"markdown","source":["<b>2. Creating Placeholders</b>"]},{"metadata":{"id":"9aM6fyvd5I1e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["X = tf.placeholder(dtype=tf.float32,shape=[None,3]) \n","Y_Expected = None # Write code to create the placeholder for target."],"execution_count":0,"outputs":[]},{"metadata":{"id":"IIcGDu2s5I1f","colab_type":"text"},"cell_type":"markdown","source":["<b>3. Creating Variables</b>"]},{"metadata":{"id":"OJd_anpk5I1h","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["b = tf.Variable(dtype=tf.float32,initial_value=np.zeros(shape=(1,1)),name=\"b\")\n","W = None # Write code to instantiate W with zeros. "],"execution_count":0,"outputs":[]},{"metadata":{"id":"cZItc9VZ5I1k","colab_type":"text"},"cell_type":"markdown","source":["<b> 4. Creating Compute Graph </b>"]},{"metadata":{"id":"HwpRYAc85I1k","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["Y = None # Define the equation to compute the output variable.\n","cost = None # Define the cost function.  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"XoqEq-Mj5I1m","colab_type":"text"},"cell_type":"markdown","source":["<b> 5. Training and optimizer </b>"]},{"metadata":{"id":"TkF3TNpt5I1o","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# This part has been done for you already! Just run it after you finish coding the above sections. \n","sess = tf.InteractiveSession()\n","sess.run(tf.global_variables_initializer())\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n","train_op = optimizer.minimize(cost)\n","for epoch in range(30):\n","    epoch_cost,_ = sess.run([cost,train_op],feed_dict={X:x,Y_Expected:y})\n","    print epoch,epoch_cost"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nnMq3Dxx5I1q","colab_type":"text"},"cell_type":"markdown","source":["<b> 5. Print out parameters </b>"]},{"metadata":{"id":"Htz0trvg5I1s","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Replace the None with the correct operation. You should get W close to [[1],[2],[3]] and b close to 10. \n","print(\"W:\",None)\n","print(\"b:\",None)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1xXx4-CO5I1v","colab_type":"text"},"cell_type":"markdown","source":["### II. Matrix Multiplication"]},{"metadata":{"id":"0ZylKoT7v9J2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def ndmatmul():\n","    \"\"\"\n","      # 3d x 2d Matmul operation. \n","      You may find some of these functions useful: einsum, tile, expand_dims.\n","      :return a: Placeholder for 3d tensor [float64]\n","              b: Placeholder for 2d tensor [float64]\n","              c: Matrix Product\n","      \"\"\"\n","    a = None\n","    b = None\n","    c = None\n","    return a,b,c"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oHHeXiBOxyI2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["A,B,C = ndmatmul()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rldu3MIfx3Yi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["np.random.seed(1)\n","a = np.random.randn(5,2,3)\n","b = np.random.randn(3,1)\n","c = np.matmul(a,b)\n","print(a.shape)\n","print(b.shape)\n","print(c.shape)\n","print(c)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BX2VDVzx01vp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Will give error if function not implemented. Your output should match Numpy's output.\n","sess = tf.InteractiveSession()\n","c_tensor = sess.run(C,feed_dict={A:a,\n","                            B:b})\n","print(c_tensor)\n","if (c_tensor-c<10**-10).all():\n","    print(\"Correct!\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M_B3PwLX2mYc","colab_type":"text"},"cell_type":"markdown","source":["### III. Experiments with Feed-forward NN on MNIST"]},{"metadata":{"id":"cX231VZk5I13","colab_type":"text"},"cell_type":"markdown","source":["In this Qn, you will experiment with Feed-forward Neural nets while training on the MNIST dataset. Read more about it <a href = \"https://en.wikipedia.org/wiki/MNIST_database\">here</a>. A random sample of the images has been shown to you. "]},{"metadata":{"id":"GX5Q-nJv5I14","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Load MNIST Data\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n","train_data = mnist.train.images # Returns np.array\n","train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n","eval_data = mnist.test.images # Returns np.array\n","eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n","print(train_data.shape)\n","print(train_labels.shape)\n","print(eval_data.shape)\n","print(eval_labels.shape)\n","# Randomly choose 10 images from first 50 images of Train Data.\n","for index,idx in enumerate(random.sample(range(50),10)): \n","    plt.subplot(10,1,index+1)\n","    plt.imshow(train_data[idx].reshape(28,28))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W6I1p3uH5I18","colab_type":"text"},"cell_type":"markdown","source":["Fill in the following snippet as per the instructions. \n","* For initialising placeholders, use None to accommodate variable batch_size. \n","* Do not change the seed; use it for comparing epoch-wise loss with your friends.\n","* You can use the following <a href =\"https://www.tensorflow.org/versions/r1.1/get_started/mnist/beginners\">tutorial</a> for reference. Note that they use softmax in their example, while you are required to code Feedforward neural network. \n"]},{"metadata":{"id":"IqWoBVW9276e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def initializer_1(shape):\n","    # Do not change the seed. \n","    np.random.seed(1)\n","    return np.random.randn(*shape)\n","\n","def initializer_2(shape):\n","    # Do not change the seed.\n","    np.random.seed(1)\n","    return 0.01 * np.random.randn(*shape)\n","\n","class MNIST_ANN:\n","    def __init__(self,hidden_units,activations,initializer):\n","        \"\"\"\n","        Initialise the weights and build the compute graph. Use AdamOptimizer with default parameters.\n","        :param hidden_units - list of number of hidden units. \n","               Eg: [10,20] => Layer 1 has 10 hidden units and Layer 2 has 20.\n","        :param activations - list of activations for each of the hidden layers.\n","               Eg: [tf.nn.sigmoid, tf.nn.tanh]\n","        :param intializer - the reference to the function used for intializing the weights\n","        \"\"\"\n","        # Define the placeholders\n","        self.input = None\n","        self.expected_output = None\n","        \n","        # Initialise the weights and biases. Use zeros for the biases. \n","        weights = []\n","        biases = []\n","        \n","        # Loop here.\n","        None\n","        \n","        # Build the graph for computing output.\n","        self.output = None\n","        \n","        # Define the loss and accuracy here. (Refer Tutorial)\n","        self.cost = None\n","        self.accuracy = None\n","        \n","        # Instantiate the optimizer\n","        optimizer = None\n","        self.train_op = optimizer.minimize(self.cost)\n","        self.session = tf.Session()\n","        \n","        # Initialize all variables\n","        None\n","    \n","    def train(self,train_data,train_labels,eval_data,eval_labels,batch_size,epochs=100):\n","        \"\"\"\n","        Training code.\n","        \"\"\"\n","        sess = self.session\n","\n","        # Slice the data and labels into batches depending on the batch_size.\n","        batches = []\n","        \n","        for epoch in range(epochs):\n","            cost_epoch = 0\n","            for batch in batches:\n","                # Forward Propagate, compute cost and backpropagate.\n","                cost,_ = sess.run([self.cost,self.train_op],feed_dict={self.input:None,\n","                                                             self.expected_output: None})\n","                cost_epoch += cost\n","            if epoch%10 == 0:\n","                print(\"Train accuracy: {}\".format(self.compute_accuracy(train_data,train_labels)))        \n","                print(\"Test accuracy: {}\".format(self.compute_accuracy(eval_data,eval_labels)))\n","            print(\"Epoch {}: {}\".format(epoch,cost_epoch))\n","        print(\"Train accuracy: {}\".format(self.compute_accuracy(train_data,train_labels)))\n","        print(\"Test accuracy: {}\".format(self.compute_accuracy(eval_data,eval_labels)))\n","\n","    def compute_accuracy(self,data,labels):\n","        \"\"\"\n","        Fill in code to compute accuracy\n","        \"\"\"\n","        pass"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_TTASFUA5I1_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["ann = MNIST_ANN([10],[tf.nn.sigmoid],initializer_1)\n","ann.train(train_data,train_labels,eval_data,eval_labels,batch_size=10,epochs=3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"maX6s20Q5I2B","colab_type":"text"},"cell_type":"markdown","source":["The expected output for the above snippet is\n","<pre>\n","Train accuracy: 0.780763626099\n","Test accuracy: 0.791599988937\n","Epoch 0: 6768.86486949\n","Epoch 1: 3275.00310887\n","Epoch 2: 2590.16959983\n","Train accuracy: 0.873399972916\n","Test accuracy: 0.876900017262\n","</pre>\n","If you get any other output and you feel you are correct, you can proceed (However, I cannot think of any case where you can get a different output). "]},{"metadata":{"id":"iJv-fmOh5I2B","colab_type":"text"},"cell_type":"markdown","source":["### Answer the following questions by running code snippets. Unless asked explicitly (like in Q1 and Q4), you need to just show the system performance and need not comment."]},{"metadata":{"id":"mmfIKKtm5I2D","colab_type":"text"},"cell_type":"markdown","source":["**1. Use 1 hidden layer of 10 hidden units with sigmoid activation and batch_size=10 for this question. Observe the network performance for initializer_1 and initializer_2 and explain the behavior. Why does this happen? What is your guess for tanh and relu? Why?**"]},{"metadata":{"id":"IQ-60H-X5I2D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Your code here. "],"execution_count":0,"outputs":[]},{"metadata":{"id":"eysUpIUF5I2H","colab_type":"text"},"cell_type":"markdown","source":["<b>2. Play around with different configurations of the system. Spend some time on <a href=\"https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.52239&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\"> Tensorflow Playground </a> to get a feel. Just demonstrate the performance of the system and make observations. No need to make any comments. </b>"]},{"metadata":{"id":"CYr-ppoI5I2H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Your code here."],"execution_count":0,"outputs":[]},{"metadata":{"id":"GE-NMOxC5I2J","colab_type":"text"},"cell_type":"markdown","source":["<b>4. List the problems you faced while experimenting [Loss did not decrease, ran into NaNs, etc]. What conclusions did you make? </b>"]},{"metadata":{"id":"aRZAGPJ-5I2L","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}